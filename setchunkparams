This function determines how the specified number of photon packages should be split over chunks, and stores the resulting parameters in protected data members. It should be called at the start of each photon shooting phase.

A chunk is the unit of parallelization in the simulation, i.e. multiple chunks may be performed simultaneously in different execution threads. The number of photons launched in a chunk, called the chunk size, is the same for all chunks in the simulation. All photon packages in a chunk have the same wavelength. Increasing the number of chunks per wavelength artificially increases the number of work units, giving a better load balancing between threads. If no photon packages must be launched for the simulation, the number of chunks is trivially zero. If the number of photon packages is nonzero, we will determine the number of chunks based on several criteria.

-# If there is only one thread per process, each process will just run through the wavelengths serially, and hence no load balancing improvements can be gained by increasing the number of chunks. The number of chunks per process should be 1.

-# When multithreading is used, we want the total number of work units per process to be larger than 10 times the amount of threads. This condition can be written as:
\f[\boxed{ \frac{N_\text{chunks} \times N_\lambda}{N_{procs}} > 10\times N_\text{threads} }\f] To further enhance the load balancing, we additionally enforce the chunks to not consist of more than \f$S_\text{max}=10^7\f$ photon packages: \f[\boxed{N_\text{chunks} > \frac{N_\text{pp}}{S_\text{max}}}\f] For the total number of chunks, we take \f[ \boxed{N_\text{chunks} > 10 \times \frac{N_\text{threads} \times N_\text{procs}}{N_\lambda}} \f]

-# For the final step, we need to look at whether data parallelization is active. 
    - When data parallelization is used, each process will only handle a particular subset of about \f$\frac{1}{N_\text{procs}}\f$ of the wavelengths. Thus each process will only do about \f$\frac{1}{N_\text{procs}}\f$ of the work units contained in every chunk it processes. Therefore, the number of chunks for each process is set equal to the total number of chunks.
    - When data parallelization is not active, each process will do all the wavelengths for every chunk it gets. Therefore, instead of distributing the work units by wavelengths, we distribute them by chunks. The total amount of chunks (\f$N_\text{chunks}\f$) is first rounded up to a multiple of \f$N_\text{procs}\f$, and the number of chunks per process becomes \f$\frac{N_\text{chunks}}{N_\text{procs}}\f$.

After this, the number of photon packages per chunk becomes \f$\frac{N_\text{pp}}{N_\text{chunks}}\f$, making sure that 